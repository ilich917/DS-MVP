{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Importar bibliotecas / Import Libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import keras\n",
    "import numpy as np \n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.models import Sequiential\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as pyplot\n",
    "from sklearn.externals import joblib\n",
    "import itertools"
   ]
  },
  {
   "source": [
    "# Cargar dataset / Loading dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_main = pd.read_csv('./output/new_dataset_1.csv', index_col = 0)\n",
    "dataset_main.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataset_main.iloc[:, -1].values\n",
    "y_train = []\n",
    "for l in labels:\n",
    "    y_train.append(l[-5:-4])\n",
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_x_train = dataset_main.iloc[:,:-2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_y_train = np.array(y_train)"
   ]
  },
  {
   "source": [
    "# MinMax"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = MinMaxScaler()\n",
    "print(ds_x_train)\n",
    "ds_x_train = scalar.fit_transform(ds_x_train)"
   ]
  },
  {
   "source": [
    "# Guardar scalar para usar en inferencia"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(scalar, './output/Bible_new_Minmaxscalar.pkl')"
   ]
  },
  {
   "source": [
    "# Block creation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = []\n",
    "count = 0\n",
    "for i in range(11, len(ds_y_train), 12):\n",
    "    count += 1\n",
    "    # X_train.append(ds_x_train[i-12:i,:])\n",
    "    Y_train.append(ds_y_train[i])\n",
    "Y_train = np.array(Y_train)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = int(len(ds_x_train) / 12)\n",
    "X_train = np.array(np.split(ds_x_train, blocks))\n",
    "X_train.shape"
   ]
  },
  {
   "source": [
    "## Label Encoding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "Y_train = label_encoder.fit_transform(Y_train)\n",
    "\n",
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the label encoder to use in inference\n",
    "joblib.dump(label_encoder, './Bible_label_john_adj_12d_aug3.pkl')"
   ]
  },
  {
   "source": [
    "# Spliting the training and validation data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data incase needed\n",
    "np.save('./output/x_test_18d_aug1.npy', x_test)\n",
    "np.save('./output/x_train_18d_aug1.npy', x_train)"
   ]
  },
  {
   "source": [
    "# One Hot encoding the labels"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "np.save('./output/y_test_18d_aug1.npy', y_test)\n",
    "np.save('./output/y_train_18d_aug1.npy', y_train)"
   ]
  },
  {
   "source": [
    "# Chechpoint path and early stopping configuration"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "callbacks1 = ModelCheckpoint('./output/new_dataset_SimpleLSTM,hdf5', save_best_only = True)\n",
    "callbacks2 = EarlyStopping(monitor = 'val_acc', patience = 100, vebose = 1)\n",
    "callbacks = [callbacks1, callbacks2]"
   ]
  },
  {
   "source": [
    "# Model architecture creation\n",
    "\n",
    "## Model V1 : Simple LSTM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple LSTM 8\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(34, input_shape = 12, 96), return_sequences = True, activation = 'sigmoid'))\n",
    "\n",
    "model.add(LSTM(34, activation = 'sigmoid'))\n",
    "\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(9, activation = 'softmax'))"
   ]
  },
  {
   "source": [
    "## Model V2: LSTM with Dropout"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 LSTM with dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(256, input_shape = (18, 12), activation = 'sigmoid', return_sequences = True))\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(LSTM(128, return_sequences = True, activation = 'sigmoid'))\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(LSTM(64, activation = 'sigmoid'))\n",
    "\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(9, activation = 'softmax'))\n"
   ]
  },
  {
   "source": [
    "# Training phase"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, validation_data = [x_test, y_test], epochs=600, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = label_encoder.inverse_transform(model.predict_classes(np.expand_dims(x_test[1], axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for i in range(len(y_test)):\n",
    "    output.append(label_encoder.inverse_transform(np.expand_dims(np.argmax(y_test[i]), axis=0)))\n",
    "output = np.array(output)"
   ]
  },
  {
   "source": [
    "# Confusion Matrix"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(output, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(output, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize = False, title = 'Confusion matrix', cmap = plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting 'normalize=True'.\n",
    "    \"\"\"\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print('Normalized confusion matrix')\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    \n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment = 'center',\n",
    "                    color = 'white' if cm[i, j] > thresh else 'black')\n",
    "    \n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./output/aug3_bible_3_16.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, sorted(os.listdir('./output/john_3_16/')))"
   ]
  }
 ]
}